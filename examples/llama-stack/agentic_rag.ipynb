{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77893d0a",
   "metadata": {},
   "source": [
    "# Agentic RAG with Llama Stack\n",
    "\n",
    "This notebook highlights how to integrate **Docling MCP** tools in the Agentic RAG available in Llama Stack.\n",
    "\n",
    "We will use the Llama Stack framework. To get an introduction to Llama Stack capabilities, including its current builtin tools, you can refer to the\n",
    "[Llama Stack Demos on OpenDataHub](https://github.com/opendatahub-io/llama-stack-demos) repository.\n",
    "\n",
    "This example will use the inline Milvus component available in the Llama Stack distributions.\n",
    "\n",
    "### Tools:\n",
    "\n",
    "We will use tools internal to Llama Stack and from the Docling MCP server that allow executing tasks such as:\n",
    "- [`mcp:docling`] converting a PDF file from a local or remote location into a unified document representation [DoclingDocument](https://docling-project.github.io/docling/concepts/docling_document/).\n",
    "- [`mcp:docling`] chunk and ingest the document in the Llama Stack vectordb.\n",
    "- [`builtin::rag/knowledge_search`] search in the document using agentic rag techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30845564",
   "metadata": {},
   "source": [
    "## Pre-Requisites\n",
    "\n",
    "Before starting this notebook, ensure that you have:\n",
    "- Followed the instructions in the [README.md](./README.md) file to set up the following resources:\n",
    "  - Inference model with Ollama\n",
    "  - Llama Stack server with the Ollama template [distribution-starter](https://hub.docker.com/r/llamastack/distribution-starter)\n",
    "  - Docling MCP server \n",
    "\n",
    "You may want to create a virtual environment to run this notebook, for instance, with [uv](https://docs.astral.sh/uv/). Ensure to install the llama-stack optional dependencies, as well as the examples group dependencies:\n",
    "\n",
    "```bash\n",
    "uv venv\n",
    "source .venv/bin/activate\n",
    "uv sync --extra llama-stack --group examples\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88519a5",
   "metadata": {},
   "source": [
    "\n",
    "## Setting Up this Notebook\n",
    "\n",
    "Rename or copy the [`.env.example`](./.env.examples) file to create a new file called `.env`. Most environmental variables are already set up with default values to run this notebook and they are aligned to the set up of the pre-requisites, like the Llama Stack server and the Docling MCP endpoints.\n",
    "\n",
    "```bash\n",
    "cp .env.example .env\n",
    "```\n",
    "\n",
    "### Environment variables required for this notebook\n",
    "\n",
    "- `BASE_URL`: the URL of the remote Llama Stack server. Defaults to `http://localhost:8321`.\n",
    "- `INFERENCE_MODEL`: the generative AI model id. Defaults to the Meta Llama 3.2 model (`meta-llama/Llama-3.2-3B-Instruct`).\n",
    "- `TEMPERATURE` (optional): the temperature to use during inference. Defaults to 0.0.\n",
    "- `TOP_P` (optional): the top_p parameter to use during inference. Defaults to 0.95.\n",
    "- `MAX_TOKENS` (optional): the maximum number of tokens that can be generated in the completion. Defaults to 4096.\n",
    "- `STREAM` (optional): set this to True to stream the output of the model/agent and False otherwise. Defaults to True.\n",
    "- `USE_PROMPT_CHAINING`: dictates if the prompt should be formatted as a few separate prompts to isolate each step or in a single turn.\n",
    "- `DOCLING_MCP_URL`: the URL for the Docling MCP server. If the client does not find the tool registered to the llama-stack instance, it will use this URL to register it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ad7d58",
   "metadata": {},
   "source": [
    "## Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07424c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Settings</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">base_url</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AnyHttpUrl</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'http://localhost:8321/'</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">inference_model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'ollama/llama3.2:3b-instruct-fp16'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">top_p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">stream</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">use_prompt_chaining</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">docling_mcp_url</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AnyHttpUrl</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'http://host.containers.internal:8000/mcp'</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">vdb_provider</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'milvus'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">vdb_embedding</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'all-MiniLM-L6-v2'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">vdb_embedding_dimension</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSettings\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mbase_url\u001b[0m=\u001b[1;35mAnyHttpUrl\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'http://localhost:8321/'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33minference_model\u001b[0m=\u001b[32m'ollama/llama3.2:3b-instruct-fp16'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mmax_tokens\u001b[0m=\u001b[1;36m4096\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mtop_p\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.95\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mstream\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33muse_prompt_chaining\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mdocling_mcp_url\u001b[0m=\u001b[1;35mAnyHttpUrl\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'http://host.containers.internal:8000/mcp'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mvdb_provider\u001b[0m=\u001b[32m'milvus'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mvdb_embedding\u001b[0m=\u001b[32m'all-MiniLM-L6-v2'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mvdb_embedding_dimension\u001b[0m=\u001b[1;36m384\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "import uuid\n",
    "\n",
    "from llama_stack_client import Agent\n",
    "from llama_stack_client import LlamaStackClient\n",
    "from llama_stack_client.lib.agents.event_logger import EventLogger\n",
    "from llama_stack_client.lib.agents.react.agent import ReActAgent\n",
    "from llama_stack_client.lib.agents.react.tool_parser import ReActOutput\n",
    "from pydantic import NonNegativeFloat, AnyHttpUrl\n",
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "from rich.pretty import pprint\n",
    "\n",
    "from src.utils import step_printer, user_printer\n",
    "\n",
    "# set the logger\n",
    "logger = logging.getLogger(__name__)\n",
    "if not logger.hasHandlers():\n",
    "    logger.setLevel(logging.INFO)\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter(\"%(message)s\")\n",
    "    stream_handler.setFormatter(formatter)\n",
    "    logger.addHandler(stream_handler)\n",
    "\n",
    "\n",
    "# access the environment variables\n",
    "class Settings(BaseSettings):\n",
    "    base_url: AnyHttpUrl = \"http://localhost:8321\"\n",
    "    inference_model: str = \"ollama/llama3.2:3b-instruct-fp16\"\n",
    "    max_tokens: int = 4096\n",
    "    temperature: NonNegativeFloat = 0.0\n",
    "    top_p: float = 0.95\n",
    "    stream: bool = False\n",
    "    use_prompt_chaining: bool = True\n",
    "\n",
    "    docling_mcp_url: AnyHttpUrl = \"http://host.containers.internal:8000/mcp\"\n",
    "\n",
    "    vdb_provider: str = \"milvus\"\n",
    "    vdb_embedding: str = \"all-MiniLM-L6-v2\"\n",
    "    vdb_embedding_dimension: int = 384\n",
    "    # vdb_embedding_window: int = 256\n",
    "\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file=\".env\", env_file_encoding=\"utf-8\", extra=\"ignore\"\n",
    "    )\n",
    "\n",
    "\n",
    "settings = Settings()\n",
    "pprint(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad79b36",
   "metadata": {},
   "source": [
    "## Setting Up the Server Connection\n",
    "\n",
    "Establish the connection to your Llama Stack server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f698f34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Llama Stack server @ http://localhost:8321/\n"
     ]
    }
   ],
   "source": [
    "client = LlamaStackClient(base_url=str(settings.base_url))\n",
    "print(f\"Connected to Llama Stack server @ {client.base_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed93b8e9",
   "metadata": {},
   "source": [
    "## Initializing the Inference Parameters\n",
    "\n",
    "Fetch the inference-related parameters from the corresponding environment variables and convert them to the format Llama Stack expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2dee538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Parameters:\n",
      "\tSampling Parameters: {'strategy': {'type': 'greedy'}, 'max_tokens': 4096}\n",
      "\tstream: False\n"
     ]
    }
   ],
   "source": [
    "if settings.temperature > 0.0:\n",
    "    strategy = {\n",
    "        \"type\": \"top_p\",\n",
    "        \"temperature\": settings.temperature,\n",
    "        \"top_p\": settings.top_p,\n",
    "    }\n",
    "else:\n",
    "    strategy = {\"type\": \"greedy\"}\n",
    "\n",
    "# sampling_params will later be used to pass the parameters to Llama Stack Agents/Inference APIs\n",
    "sampling_params = {\n",
    "    \"strategy\": strategy,\n",
    "    \"max_tokens\": settings.max_tokens,\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"Inference Parameters:\\n\\tSampling Parameters: {sampling_params}\\n\\tstream: {settings.stream}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eba1f1",
   "metadata": {},
   "source": [
    "## Validate that the Docling MCP tools are available in the Llama Stack instance\n",
    "\n",
    "When an instance of Llama Stack is redeployed, it may be the case that the tools will need to be re-registered. Also if a tool is already registered with a Llama Stack instance, trying to register another one with the same `toolgroup_id` will throw you an error.\n",
    "\n",
    "For this reason, it is recommended to validate your tools and toolgroups. The following code will check that `mcp::docling` tools are correctly registered, and if not it will attempt to register them using their specific endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa74729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1/tools \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1/tools \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Llama Stack server is registered with the following tool groups @ {'builtin::websearch', 'mcp::docling', 'builtin::rag'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "registered_tools = client.tools.list()\n",
    "registered_toolgroups = [t.toolgroup_id for t in registered_tools]\n",
    "if \"mcp::docling\" not in registered_toolgroups:\n",
    "    client.toolgroups.register(\n",
    "        toolgroup_id=\"mcp::docling\",\n",
    "        provider_id=\"model-context-protocol\",\n",
    "        mcp_endpoint={\"uri\": str(settings.docling_mcp_url)},\n",
    "    )\n",
    "\n",
    "registered_tools = client.tools.list()\n",
    "registered_toolgroups = [t.toolgroup_id for t in registered_tools]\n",
    "print(\n",
    "    f\"Your Llama Stack server is registered with the following tool groups @ {set(registered_toolgroups)} \\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab507be",
   "metadata": {},
   "source": [
    "## Defining our Agent - Prompt Chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aec5c8c",
   "metadata": {},
   "source": [
    "We define an agent provided with the **Docling MCP** tools together with the built-in knowledge_search. The agent should be able to accomplish the following tasks in a multi-step, multi-tool approach:\n",
    "\n",
    "1. Converting a PDF file into the `DoclingDocument` format.\n",
    "2. Ingest the results in the vector db.\n",
    "3. Search in the vector db using an agentic/multi-step approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3a8e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prompt = \"\"\"You are a helpful assistant. You have access to a number of tools.\n",
    "Whenever a tool is called, be sure to return the Response in a friendly and helpful tone.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39e0e316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/vector-dbs \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1/tools?toolgroup_id=mcp%3A%3Adocling%2Fconvert_pdf_document_into_docling_document \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1/tools?toolgroup_id=mcp%3A%3Adocling%2Finsert_document_to_vectordb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1/tools?toolgroup_id=builtin%3A%3Arag%2Fknowledge_search \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# define the name of the vectordb collection to use\n",
    "vector_db_id = f\"test_vector_db_{uuid.uuid4()}\"\n",
    "\n",
    "# define and register the document collection to be used\n",
    "client.vector_dbs.register(\n",
    "    vector_db_id=vector_db_id,\n",
    "    embedding_model=settings.vdb_embedding,\n",
    "    embedding_dimension=settings.vdb_embedding_dimension,\n",
    "    provider_id=settings.vdb_provider,\n",
    ")\n",
    "\n",
    "\n",
    "# Create simple agent with tools\n",
    "agent = Agent(\n",
    "    client=client,\n",
    "    model=settings.inference_model,  # replace this with model_id to get the value of INFERENCE_MODEL_ID environment variable\n",
    "    instructions=model_prompt,  # update system prompt based on the model you are using\n",
    "    tools=[\n",
    "        dict(\n",
    "            name=\"mcp::docling/convert_pdf_document_into_docling_document\",\n",
    "            args={},\n",
    "        ),\n",
    "        dict(\n",
    "            name=\"mcp::docling/insert_document_to_vectordb\",\n",
    "            args={\n",
    "                \"vector_db_id\": vector_db_id,\n",
    "            },\n",
    "        ),\n",
    "        dict(\n",
    "            name=\"builtin::rag/knowledge_search\",\n",
    "            args={\n",
    "                \"vector_db_ids\": [\n",
    "                    vector_db_id\n",
    "                ],  # list of IDs of document collections to consider during retrieval\n",
    "            },\n",
    "        ),\n",
    "    ],\n",
    "    tool_config={\"tool_choice\": \"auto\"},\n",
    "    sampling_params=sampling_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a69aab5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents/bb6c105b-8528-4c6a-930a-9c90f36da2b7/session \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents/bb6c105b-8528-4c6a-930a-9c90f36da2b7/session/263c4dbf-fe54-4afd-8e2e-ae29cd2147a5/turn \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👤 User Query:\n",
      "\u001b[36mConvert the PDF document on https://arxiv.org/pdf/2206.01062 to DoclingDocument.\u001b[0m\n",
      "\n",
      "---------- 📍 Step 1: InferenceStep ----------\n",
      "🛠️ Tool call Generated:\n",
      "\u001b[35mTool call: convert_pdf_document_into_docling_document, Arguments: {'source': 'https://arxiv.org/pdf/2206.01062'}\u001b[0m\n",
      "\n",
      "---------- 📍 Step 2: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\\n  \"success\": true,\\n  \"document_key\": \"868f49ae1f0e66e82238a8aea43fd30b\"\\n}'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n  \"success\": true,\\n  \"document_key\": \"868f49ae1f0e66e82238a8aea43fd30b\"\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents/bb6c105b-8528-4c6a-930a-9c90f36da2b7/session/263c4dbf-fe54-4afd-8e2e-ae29cd2147a5/turn \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 3: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35mThe PDF document has been successfully converted to a Docling document and stored in the local cache. The unique key for this document is '868f49ae1f0e66e82238a8aea43fd30b'. You can use this key to insert the document into a vector database or perform knowledge searches on it.\n",
      "\u001b[0m\n",
      "========== Query processing completed ========== \n",
      "\n",
      "👤 User Query:\n",
      "\u001b[36mIngest the document.\u001b[0m\n",
      "\n",
      "---------- 📍 Step 1: InferenceStep ----------\n",
      "🛠️ Tool call Generated:\n",
      "\u001b[35mTool call: insert_document_to_vectordb, Arguments: {'document_key': '868f49ae1f0e66e82238a8aea43fd30b', 'vector_db_id': 'my_vector_db'}\u001b[0m\n",
      "\n",
      "---------- 📍 Step 2: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\\n  \"vector_db_id\": \"test_vector_db_2d8d7eb5-d0c6-4970-adab-4e72d6d980f7\"\\n}'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n  \"vector_db_id\": \"test_vector_db_2d8d7eb5-d0c6-4970-adab-4e72d6d980f7\"\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents/bb6c105b-8528-4c6a-930a-9c90f36da2b7/session/263c4dbf-fe54-4afd-8e2e-ae29cd2147a5/turn \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 3: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35mThe document has been successfully ingested into the vector database. The unique identifier for this vector database is 'test_vector_db_2d8d7eb5-d0c6-4970-adab-4e72d6d980f7'. You can now use this vector database to perform knowledge searches on the converted PDF document.\n",
      "\u001b[0m\n",
      "========== Query processing completed ========== \n",
      "\n",
      "👤 User Query:\n",
      "\u001b[36mAnswer with the document knowledge in the vectordb: How many pages were manually annotated?\u001b[0m\n",
      "\n",
      "---------- 📍 Step 1: InferenceStep ----------\n",
      "🛠️ Tool call Generated:\n",
      "\u001b[35mTool call: knowledge_search, Arguments: {'query': 'number of pages manually annotated in 2206.01062'}\u001b[0m\n",
      "\n",
      "---------- 📍 Step 2: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'knowledge_search tool found 5 chunks:\\nBEGIN of knowledge_search tool results.\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Result 1\\nContent: 3 THE DOCLAYNET DATASET\\nDocLayNet contains 80863 PDF pages. Among these, 7059 carry two instances of human annotations, and 1591 carry three. This amounts to 91104 total annotation instances. The annotations provide layout information in the shape of labeled, rectangular boundingboxes. We define 11 distinct labels for layout features, namely Caption , Footnote , Formula , List-item , Page-footer , Page-header , Picture , Section-header , Table , Text , and Title . Our reasoning for picking this particular label set is detailed in Section 4.\\nIn addition to open intellectual property constraints for the source documents, we required that the documents in DocLayNet adhere to a few conditions. Firstly, we kept scanned documents\\nFigure 2: Distribution of DocLayNet pages across document categories.\\nMetadata: {'chunk_id': '7156212269791437020-00012', 'document_id': '7156212269791437020', 'source': None, 'doc_items': ['#/texts/339', '#/texts/340', '#/texts/343']}\\n\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Result 2\\nContent: 4 ANNOTATION CAMPAIGN\\nwere carried out over a timeframe of 12 weeks, after which 8 of the 40 initially allocated annotators did not pass the bar.\\nPhase 4: Production annotation. The previously selected 80K pages were annotated with the defined 11 class labels by 32 annotators. This production phase took around three months to complete. All annotations were created online through CCS, which visualises the programmatic PDF text-cells as an overlay on the page. The page annotation are obtained by drawing rectangular bounding-boxes, as shown in Figure 3. With regard to the annotation practices, we implemented a few constraints and capabilities on the tooling level. First, we only allow non-overlapping, vertically oriented, rectangular boxes. For the large majority of documents, this constraint was sufficient and it speeds up the annotation considerably in comparison with arbitrary segmentation shapes. Second, annotator staff were not able to see each other's annotations. This was enforced by design to avoid any bias in the annotation, which could skew the numbers of the inter-annotator agreement (see Table 1). We wanted\\nMetadata: {'chunk_id': '7156212269791437020-00039', 'document_id': '7156212269791437020', 'source': None, 'doc_items': ['#/texts/422', '#/texts/423']}\\n\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Result 3\\nContent: 4 ANNOTATION CAMPAIGN\\nThe annotation campaign was carried out in four phases. In phase one, we identified and prepared the data sources for annotation. In phase two, we determined the class labels and how annotations should be done on the documents in order to obtain maximum consistency. The latter was guided by a detailed requirement analysis and exhaustive experiments. In phase three, we trained the annotation staff and performed exams for quality assurance. In phase four,\\n\\nTable 1: DocLayNet dataset overview. Along with the frequency of each class label, we present the relative occurrence (as % of row 'Total') in the train, test and validation sets. The inter-annotator agreement is computed as the mAP@0.5-0.95 metric between pairwise annotations from the triple-annotated pages, from which we obtain accuracy ranges.\\nMetadata: {'chunk_id': '7156212269791437020-00019', 'document_id': '7156212269791437020', 'source': None, 'doc_items': ['#/texts/365', '#/texts/367', '#/tables/0']}\\n\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Result 4\\nContent: 4 ANNOTATION CAMPAIGN\\nTotal.Train = 5.10. Page-header, % of Total.Test = 6.70. Page-header, % of Total.Val = 5.06. Page-header, triple inter-annotator mAP @0.5-0.95 (%).All = 85-89. Page-header, triple inter-annotator mAP @0.5-0.95 (%).Fin = 66-76. Page-header, triple inter-annotator mAP @0.5-0.95 (%).Man = 90-94. Page-header, triple inter-annotator mAP @0.5-0.95 (%).Sci = 98-100. Page-header, triple inter-annotator mAP @0.5-0.95 (%).Law = 91-92. Page-header, triple inter-annotator mAP @0.5-0.95 (%).Pat = 97-99. Page-header, triple inter-annotator mAP @0.5-0.95 (%).Ten = 81-86. Picture, Count = 45976. Picture, %\\nMetadata: {'chunk_id': '7156212269791437020-00025', 'document_id': '7156212269791437020', 'source': None, 'doc_items': ['#/tables/0']}\\n\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Result 5\\nContent: 4 ANNOTATION CAMPAIGN\\nPage-footer, % of Total.Test = 5.58. Page-footer, % of Total.Val = 6.00. Page-footer, triple inter-annotator mAP @0.5-0.95 (%).All = 93-94. Page-footer, triple inter-annotator mAP @0.5-0.95 (%).Fin = 88-90. Page-footer, triple inter-annotator mAP @0.5-0.95 (%).Man = 95-96. Page-footer, triple inter-annotator mAP @0.5-0.95 (%).Sci = 100. Page-footer, triple inter-annotator mAP @0.5-0.95 (%).Law = 92-97. Page-footer, triple inter-annotator mAP @0.5-0.95 (%).Pat = 100. Page-footer, triple inter-annotator mAP @0.5-0.95 (%).Ten = 96-98. Page-header, Count = 58022. Page-header, % of\\nMetadata: {'chunk_id': '7156212269791437020-00024', 'document_id': '7156212269791437020', 'source': None, 'doc_items': ['#/tables/0']}\\n\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'END of knowledge_search tool results.\\n'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The above results were retrieved to help answer the user\\'s query: \"number of pages manually annotated in 2206.01062\". Use them as supporting information only in answering this query.\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'knowledge_search tool found 5 chunks:\\nBEGIN of knowledge_search tool results.\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m\"Result\u001b[0m\u001b[32m 1\\nContent: 3 THE DOCLAYNET DATASET\\nDocLayNet contains 80863 PDF pages. Among these, 7059 carry two instances of human annotations, and 1591 carry three. This amounts to 91104 total annotation instances. The annotations provide layout information in the shape of labeled, rectangular boundingboxes. We define 11 distinct labels for layout features, namely Caption , Footnote , Formula , List-item , Page-footer , Page-header , Picture , Section-header , Table , Text , and Title . Our reasoning for picking this particular label set is detailed in Section 4.\\nIn addition to open intellectual property constraints for the source documents, we required that the documents in DocLayNet adhere to a few conditions. Firstly, we kept scanned documents\\nFigure 2: Distribution of DocLayNet pages across document categories.\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'chunk_id': '7156212269791437020-00012', 'document_id': '7156212269791437020', 'source': None, 'doc_items': \u001b[0m\u001b[32m[\u001b[0m\u001b[32m'#/texts/339', '#/texts/340', '#/texts/343'\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\"\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m\"Result\u001b[0m\u001b[32m 2\\nContent: 4 ANNOTATION CAMPAIGN\\nwere carried out over a timeframe of 12 weeks, after which 8 of the 40 initially allocated annotators did not pass the bar.\\nPhase 4: Production annotation. The previously selected 80K pages were annotated with the defined 11 class labels by 32 annotators. This production phase took around three months to complete. All annotations were created online through CCS, which visualises the programmatic PDF text-cells as an overlay on the page. The page annotation are obtained by drawing rectangular bounding-boxes, as shown in Figure 3. With regard to the annotation practices, we implemented a few constraints and capabilities on the tooling level. First, we only allow non-overlapping, vertically oriented, rectangular boxes. For the large majority of documents, this constraint was sufficient and it speeds up the annotation considerably in comparison with arbitrary segmentation shapes. Second, annotator staff were not able to see each other's annotations. This was enforced by design to avoid any bias in the annotation, which could skew the numbers of the inter-annotator agreement \u001b[0m\u001b[32m(\u001b[0m\u001b[32msee Table 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. We wanted\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'chunk_id': '7156212269791437020-00039', 'document_id': '7156212269791437020', 'source': None, 'doc_items': \u001b[0m\u001b[32m[\u001b[0m\u001b[32m'#/texts/422', '#/texts/423'\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\"\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m\"Result\u001b[0m\u001b[32m 3\\nContent: 4 ANNOTATION CAMPAIGN\\nThe annotation campaign was carried out in four phases. In phase one, we identified and prepared the data sources for annotation. In phase two, we determined the class labels and how annotations should be done on the documents in order to obtain maximum consistency. The latter was guided by a detailed requirement analysis and exhaustive experiments. In phase three, we trained the annotation staff and performed exams for quality assurance. In phase four,\\n\\nTable 1: DocLayNet dataset overview. Along with the frequency of each class label, we present the relative occurrence \u001b[0m\u001b[32m(\u001b[0m\u001b[32mas % of row 'Total'\u001b[0m\u001b[32m)\u001b[0m\u001b[32m in the train, test and validation sets. The inter-annotator agreement is computed as the mAP@0.5-0.95 metric between pairwise annotations from the triple-annotated pages, from which we obtain accuracy ranges.\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'chunk_id': '7156212269791437020-00019', 'document_id': '7156212269791437020', 'source': None, 'doc_items': \u001b[0m\u001b[32m[\u001b[0m\u001b[32m'#/texts/365', '#/texts/367', '#/tables/0'\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\"\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m\"Result\u001b[0m\u001b[32m 4\\nContent: 4 ANNOTATION CAMPAIGN\\nTotal.Train = 5.10. Page-header, % of Total.Test = 6.70. Page-header, % of Total.Val = 5.06. Page-header, triple inter-annotator mAP @0.5-0.95 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.All = 85-89. Page-header, triple inter-annotator mAP @0.5-0.95 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.Fin = 66-76. Page-header, triple inter-annotator mAP @0.5-0.95 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.Man = 90-94. Page-header, triple inter-annotator mAP @0.5-0.95 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.Sci = 98-100. Page-header, triple inter-annotator mAP @0.5-0.95 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.Law = 91-92. Page-header, triple inter-annotator mAP @0.5-0.95 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.Pat = 97-99. Page-header, triple inter-annotator mAP @0.5-0.95 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.Ten = 81-86. Picture, Count = 45976. Picture, %\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'chunk_id': '7156212269791437020-00025', 'document_id': '7156212269791437020', 'source': None, 'doc_items': \u001b[0m\u001b[32m[\u001b[0m\u001b[32m'#/tables/0'\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\"\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m\"Result\u001b[0m\u001b[32m 5\\nContent: 4 ANNOTATION CAMPAIGN\\nPage-footer, % of Total.Test = 5.58. Page-footer, % of Total.Val = 6.00. Page-footer, triple inter-annotator mAP @0.5-0.95 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.All = 93-94. Page-footer, triple inter-annotator mAP @0.5-0.95 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.Fin = 88-90. Page-footer, triple inter-annotator mAP @0.5-0.95 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.Man = 95-96. Page-footer, triple inter-annotator mAP @0.5-0.95 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.Sci = 100. Page-footer, triple inter-annotator mAP @0.5-0.95 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.Law = 92-97. Page-footer, triple inter-annotator mAP @0.5-0.95 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.Pat = 100. Page-footer, triple inter-annotator mAP @0.5-0.95 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.Ten = 96-98. Page-header, Count = 58022. Page-header, % of\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'chunk_id': '7156212269791437020-00024', 'document_id': '7156212269791437020', 'source': None, 'doc_items': \u001b[0m\u001b[32m[\u001b[0m\u001b[32m'#/tables/0'\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\"\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'END of knowledge_search tool results.\\n'\u001b[0m, \u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'The above results were retrieved to help answer the user\\'s query: \"number of pages manually annotated in 2206.01062\". Use them as supporting information only in answering this query.\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 3: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35mAccording to the search results, there are a total of 5 pages that have been manually annotated in the document 2206.01062.\n",
      "\u001b[0m\n",
      "========== Query processing completed ========== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_prompts = [\n",
    "    \"Convert the PDF document on https://arxiv.org/pdf/2206.01062 to DoclingDocument.\",\n",
    "    \"Ingest the document.\",\n",
    "    \"Answer with the document knowledge in the vectordb: How many pages were manually annotated?\",\n",
    "]\n",
    "session_id = agent.create_session(f\"docling-session_{uuid.uuid4()}\")\n",
    "\n",
    "for i, prompt in enumerate(user_prompts):\n",
    "    user_printer(prompt)\n",
    "    response = agent.create_turn(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        session_id=session_id,\n",
    "        stream=settings.stream,\n",
    "    )\n",
    "    if settings.stream:\n",
    "        for log in EventLogger().log(response):\n",
    "            log.print()\n",
    "    else:\n",
    "        step_printer(\n",
    "            response.steps\n",
    "        )  # print the steps of an agent's response in a formatted way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd0ada6",
   "metadata": {},
   "source": [
    "## Defining our Agent - ReAct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a54284",
   "metadata": {},
   "source": [
    "We can also define our agent to be more autonomous and perform the same task with a single prompt instead of a chain. To do this, we leverage Llama Stack's **ReAct agent**, which has the ability to loop through the *Reason then Act* iterations, thinking through the problem and then using tools until it determines that it's task has been completed successfully.  \n",
    "\n",
    "Unlike prompt chaining which follows fixed steps, ReAct dynamically breaks down tasks and adapts its approach based on the results of each step. This makes it more flexible and capable of handling complex, real-world queries effectively.\n",
    "\n",
    "In this example, we will leverage the generation tools of **Docling MCP** to:\n",
    "- create a new `DoclingDocument`\n",
    "- add a title and paragraphs\n",
    "- export the resulting document into a file in markdown format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214b0942",
   "metadata": {},
   "source": [
    "The purpose of the code below is just to show the instructions sent to the LLM to complete the task. They incorporate the description of the Docling MCP tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76fbe223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1/tools?toolgroup_id=mcp%3A%3Adocling \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an expert assistant who can solve any task using tool calls. You will be given a task to solve as best you can.\n",
      "To do so, you have been given access to the following tools: is_document_in_local_cache, convert_pdf_document_into_docling_document, create_new_docling_document, export_docling_document_to_markdown, save_docling_document, add_title_to_docling_document, add_section_heading_to_docling_document, add_paragraph_to_docling_document, open_list_in_docling_document, close_list_in_docling_document, add_list_items_to_list_in_docling_document, add_table_in_html_format_to_docling_document\n",
      "\n",
      "You must always respond in the following JSON format:\n",
      "{\n",
      "    \"thought\": $THOUGHT_PROCESS,\n",
      "    \"action\": {\n",
      "        \"tool_name\": $TOOL_NAME,\n",
      "        \"tool_params\": $TOOL_PARAMS\n",
      "    },\n",
      "    \"answer\": $ANSWER\n",
      "}\n",
      "\n",
      "Specifically, this json should have a `thought` key, a `action` key and an `answer` key.\n",
      "\n",
      "The `action` key should specify the $TOOL_NAME the name of the tool to use and the `tool_params` key should specify the parameters key as input to the tool.\n",
      "\n",
      "Make sure to have the $TOOL_PARAMS as a list of dictionaries in the right format for the tool you are using, and do not put variable names as input if you can find the right values.\n",
      "\n",
      "You should always think about one action to take, and have the `thought` key contain your thought process about this action.\n",
      "If the tool responds, the tool will return an observation containing result of the action. \n",
      "... (this Thought/Action/Observation can repeat N times, you should take several steps when needed. The action key must only use a SINGLE tool at a time.)\n",
      "\n",
      "You can use the result of the previous action as input for the next action.\n",
      "The observation will always be the response from calling the tool: it can represent a file, like \"image_1.jpg\". You do not need to generate them, it will be provided to you. \n",
      "Then you can use it as input for the next action. You can do it for instance as follows:\n",
      "\n",
      "Observation: \"image_1.jpg\"\n",
      "{\n",
      "    \"thought\": \"I need to transform the image that I received in the previous observation to make it green.\",\n",
      "    \"action\": {\n",
      "        \"tool_name\": \"image_transformer\",\n",
      "        \"tool_params\": [{\"name\": \"image\"}, {\"value\": \"image_1.jpg\"}]\n",
      "    },\n",
      "    \"answer\": null\n",
      "}\n",
      "\n",
      "\n",
      "To provide the final answer to the task, use the `answer` key. It is the only way to complete the task, else you will be stuck on a loop. So your final output should look like this:\n",
      "Observation: \"your observation\"\n",
      "\n",
      "{\n",
      "    \"thought\": \"you thought process\",\n",
      "    \"action\": null,\n",
      "    \"answer\": \"insert your final answer here\"\n",
      "}\n",
      "\n",
      "Here are a few examples using notional tools:\n",
      "---\n",
      "Task: \"Generate an image of the oldest person in this document.\"\n",
      "\n",
      "Your Response:\n",
      "{\n",
      "    \"thought\": \"I will proceed step by step and use the following tools: `document_qa` to find the oldest person in the document, then `image_generator` to generate an image according to the answer.\",\n",
      "    \"action\": {\n",
      "        \"tool_name\": \"document_qa\",\n",
      "        \"tool_params\": [{\"name\": \"document\"}, {\"value\": \"document.pdf\"}, {\"name\": \"question\"}, {\"value\": \"Who is the oldest person mentioned?\"}]\n",
      "    },\n",
      "    \"answer\": null\n",
      "}\n",
      "\n",
      "Your Observation: \"The oldest person in the document is John Doe, a 55 year old lumberjack living in Newfoundland.\"\n",
      "\n",
      "Your Response:\n",
      "{\n",
      "    \"thought\": \"I will now generate an image showcasing the oldest person.\",\n",
      "    \"action\": {\n",
      "        \"tool_name\": \"image_generator\",\n",
      "        \"tool_params\": [{\"name\": \"prompt\"}, {\"value\": \"A portrait of John Doe, a 55-year-old man living in Canada.\"}]\n",
      "    },\n",
      "    \"answer\": null\n",
      "}\n",
      "Your Observation: \"image.png\"\n",
      "\n",
      "{\n",
      "    \"thought\": \"I will now return the generated image.\",\n",
      "    \"action\": null,\n",
      "    \"answer\": \"image.png\"\n",
      "}\n",
      "\n",
      "---\n",
      "Task: \"What is the result of the following operation: 5 + 3 + 1294.678?\"\n",
      "\n",
      "Your Response:\n",
      "{\n",
      "    \"thought\": \"I will use python code evaluator to compute the result of the operation and then return the final answer using the `final_answer` tool\",\n",
      "    \"action\": {\n",
      "        \"tool_name\": \"python_interpreter\",\n",
      "        \"tool_params\": [{\"name\": \"code\"}, {\"value\": \"5 + 3 + 1294.678\"}]\n",
      "    },\n",
      "    \"answer\": null\n",
      "}\n",
      "Your Observation: 1302.678\n",
      "\n",
      "{\n",
      "    \"thought\": \"Now that I know the result, I will now return it.\",\n",
      "    \"action\": null,\n",
      "    \"answer\": 1302.678\n",
      "}\n",
      "\n",
      "---\n",
      "Task: \"Which city has the highest population , Guangzhou or Shanghai?\"\n",
      "\n",
      "Your Response:\n",
      "{\n",
      "    \"thought\": \"I need to get the populations for both cities and compare them: I will use the tool `search` to get the population of both cities.\",\n",
      "    \"action\": {\n",
      "        \"tool_name\": \"search\",\n",
      "        \"tool_params\": [{\"name\": \"query\"}, {\"value\": \"Population Guangzhou\"}]\n",
      "    },\n",
      "    \"answer\": null\n",
      "}\n",
      "Your Observation: ['Guangzhou has a population of 15 million inhabitants as of 2021.']\n",
      "\n",
      "Your Response:\n",
      "{\n",
      "    \"thought\": \"Now let's get the population of Shanghai using the tool 'search'.\",\n",
      "    \"action\": {\n",
      "        \"tool_name\": \"search\",\n",
      "        \"tool_params\": [{\"name\": \"query\"}, {\"value\": \"Population Shanghai\"}]\n",
      "    },\n",
      "    \"answer\": null\n",
      "}\n",
      "Your Observation: \"26 million (2019)\"\n",
      "\n",
      "Your Response:\n",
      "{\n",
      "    \"thought\": \"Now I know that Shanghai has a larger population. Let's return the result.\",\n",
      "    \"action\": null,\n",
      "    \"answer\": \"Shanghai\"\n",
      "}\n",
      "\n",
      "Above example were using notional tools that might not exist for you. You only have access to these tools:\n",
      "- is_document_in_local_cache: {'name': 'is_document_in_local_cache', 'description': 'Verify if a Docling document is already converted and in the local cache.', 'parameters': [Parameter(description='The unique identifier of the document in the local cache.', name='document_key', parameter_type='string', required=True, default=None)]}\n",
      "- convert_pdf_document_into_docling_document: {'name': 'convert_pdf_document_into_docling_document', 'description': \"Convert a PDF document from a URL or local path and store in local cache.\\n\\n    This tool takes a PDF document's URL or local file path, converts it using\\n    Docling's DocumentConverter and stores the resulting Docling document in a\\n    local cache. It returns an output with a boolean set to True along with the\\n    document's unique cache key. If the document was already in the local cache,\\n    the conversion is skipped and the output boolean is set to False.\\n    \", 'parameters': [Parameter(description='The URL or local file path to the PDF document.', name='source', parameter_type='string', required=True, default=None)]}\n",
      "- create_new_docling_document: {'name': 'create_new_docling_document', 'description': 'Create a new Docling document from a provided prompt string.\\n\\n    This function generates a new document in the local document cache with the\\n    provided prompt text. The document is assigned a unique key derived from an MD5\\n    hash of the prompt text.\\n    ', 'parameters': [Parameter(description='The prompt text to include in the new document.', name='prompt', parameter_type='string', required=True, default=None)]}\n",
      "- export_docling_document_to_markdown: {'name': 'export_docling_document_to_markdown', 'description': 'Export a document from the local document cache to markdown format.\\n\\n    This tool converts a Docling document that exists in the local cache into\\n    a markdown formatted string, which can be used for display or further processing.\\n    ', 'parameters': [Parameter(description='The unique identifier of the document in the local cache.', name='document_key', parameter_type='string', required=True, default=None)]}\n",
      "- save_docling_document: {'name': 'save_docling_document', 'description': 'Save a document from the local document cache to disk in both markdown and JSON formats.\\n\\n    This tool takes a document that exists in the local cache and saves it to the specified\\n    cache directory with filenames based on the document key. Both markdown and JSON versions\\n    of the document are saved.\\n    ', 'parameters': [Parameter(description='The unique identifier of the document in the local cache.', name='document_key', parameter_type='string', required=True, default=None)]}\n",
      "- add_title_to_docling_document: {'name': 'add_title_to_docling_document', 'description': 'Add or update the title of a document in the local document cache.\\n\\n    This tool modifies an existing document that has already been processed\\n    and stored in the local cache. It requires that the document already exists\\n    in the cache before a title can be added.\\n    ', 'parameters': [Parameter(description='The unique identifier of the document in the local cache.', name='document_key', parameter_type='string', required=True, default=None), Parameter(description='The title text to add or update to the document.', name='title', parameter_type='string', required=True, default=None)]}\n",
      "- add_section_heading_to_docling_document: {'name': 'add_section_heading_to_docling_document', 'description': 'Add a section heading to an existing document in the local document cache.\\n\\n    This tool inserts a section heading with the specified heading text and level\\n    into a document that has already been processed and stored in the local cache.\\n    Section levels typically represent heading hierarchy (e.g., 1 for H1, 2 for H2).\\n    ', 'parameters': [Parameter(description='The unique identifier of the document in the local cache.', name='document_key', parameter_type='string', required=True, default=None), Parameter(description='The text to use for the section heading.', name='section_heading', parameter_type='string', required=True, default=None), Parameter(description='The level of the heading, starting from 1, where 1 is the highest level.', name='section_level', parameter_type='integer', required=True, default=None)]}\n",
      "- add_paragraph_to_docling_document: {'name': 'add_paragraph_to_docling_document', 'description': 'Add a paragraph of text to an existing document in the local document cache.\\n\\n    This tool inserts a new paragraph under the specified section header and level\\n    into a document that has already been processed and stored in the cache.\\n    ', 'parameters': [Parameter(description='The unique identifier of the document in the local cache.', name='document_key', parameter_type='string', required=True, default=None), Parameter(description='The text content to add as a paragraph.', name='paragraph', parameter_type='string', required=True, default=None)]}\n",
      "- open_list_in_docling_document: {'name': 'open_list_in_docling_document', 'description': \"Open a new list group in an existing document in the local document cache.\\n\\n    This tool creates a new list structure within a document that has already been\\n    processed and stored in the local cache. It requires that the document already exists\\n    and that there is at least one item in the document's stack cache.\\n    \", 'parameters': [Parameter(description='The unique identifier of the document in the local cache.', name='document_key', parameter_type='string', required=True, default=None)]}\n",
      "- close_list_in_docling_document: {'name': 'close_list_in_docling_document', 'description': \"Closes a list group in an existing document in the local document cache.\\n\\n    This tool closes a previously opened list structure within a document.\\n    It requires that the document exists and that there is more than one item\\n    in the document's stack cache.\\n    \", 'parameters': [Parameter(description='The unique identifier of the document in the local cache.', name='document_key', parameter_type='string', required=True, default=None)]}\n",
      "- add_list_items_to_list_in_docling_document: {'name': 'add_list_items_to_list_in_docling_document', 'description': \"Add list items to an open list in an existing document in the local document cache.\\n\\n    This tool inserts new list items with the specified text and marker into an\\n    open list within a document. It requires that the document exists and that\\n    there is at least one item in the document's stack cache.\\n    \", 'parameters': [Parameter(description='The unique identifier of the document in the local cache.', name='document_key', parameter_type='string', required=True, default=None), Parameter(description='A list of list_item_text and list_marker_text items.', name='list_items', parameter_type='array', required=True, default=None)]}\n",
      "- add_table_in_html_format_to_docling_document: {'name': 'add_table_in_html_format_to_docling_document', 'description': 'Add an HTML-formatted table to an existing document in the local document cache.\\n\\n    This tool parses the provided HTML table string, converts it to a structured table\\n    representation, and adds it to the specified document. It also supports optional\\n    captions and footnotes for the table.\\n    ', 'parameters': [Parameter(description='The unique identifier of the document in the local cache.', name='document_key', parameter_type='string', required=True, default=None), Parameter(description='The HTML string representation of the table to add.', name='html_table', parameter_type='string', required=True, default=None), Parameter(description='A list of caption strings to associate with the table..', name='table_captions', parameter_type='string', required=True, default=None), Parameter(description='A list of footnote strings to associate with the table.', name='table_footnotes', parameter_type='string', required=True, default=None)]}\n",
      "\n",
      "Here are the rules you should always follow to solve your task:\n",
      "1. ALWAYS answer in the JSON format with keys \"thought\", \"action\", \"answer\", else you will fail. \n",
      "2. Always use the right arguments for the tools. Never use variable names in the 'tool_params' field, use the value instead.\n",
      "3. Call a tool only when needed: do not call the search agent if you do not need information, try to solve the task yourself.\n",
      "4. Never re-do a tool call that you previously did with the exact same parameters.\n",
      "5. Observations will be provided to you, no need to generate them\n",
      "\n",
      "Now Begin! If you solve the task correctly, you will receive a reward of $1,000,000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ReAct instructions\n",
    "from llama_stack_client.lib.agents.agent import AgentUtils\n",
    "from llama_stack_client.lib.agents.react.agent import get_default_react_instructions\n",
    "\n",
    "client_tools = AgentUtils.get_client_tools([\"mcp::docling\"])\n",
    "instructions = get_default_react_instructions(client, [\"mcp::docling\"], client_tools)\n",
    "print(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "771c451f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1/tools?toolgroup_id=mcp%3A%3Adocling \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8321/v1/tools?toolgroup_id=mcp%3A%3Adocling \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents/00b00d76-1313-46cd-af96-4d9139a47641/session \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents/00b00d76-1313-46cd-af96-4d9139a47641/session/6268416b-0db6-431e-ab87-d31e9a10ea13/turn \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "👤 User Query:\n",
      "\u001b[36mI want you to create a new Docling document on Quantum Computing.\n",
      "    To do this, you will create a document by invoking `create_new_docling_document` with Quantum Computing as prompt.\n",
      "    Add a title and 3 paragraphs describing the topic, one by one, e.g. using the add_x_to_docling_document tools.\n",
      "    At the end of the writing, you must save the document by calling `save_docling_document` and return me the filepath of\n",
      "    the saved document in markdown format provided by the last tool.\n",
      "    \u001b[0m\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/tool-runtime/invoke \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents/00b00d76-1313-46cd-af96-4d9139a47641/session/6268416b-0db6-431e-ab87-d31e9a10ea13/turn/0c12d6df-314c-446d-ac68-8f1dd34475a8/resume \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/tool-runtime/invoke \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents/00b00d76-1313-46cd-af96-4d9139a47641/session/6268416b-0db6-431e-ab87-d31e9a10ea13/turn/0c12d6df-314c-446d-ac68-8f1dd34475a8/resume \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/tool-runtime/invoke \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents/00b00d76-1313-46cd-af96-4d9139a47641/session/6268416b-0db6-431e-ab87-d31e9a10ea13/turn/0c12d6df-314c-446d-ac68-8f1dd34475a8/resume \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/tool-runtime/invoke \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents/00b00d76-1313-46cd-af96-4d9139a47641/session/6268416b-0db6-431e-ab87-d31e9a10ea13/turn/0c12d6df-314c-446d-ac68-8f1dd34475a8/resume \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/tool-runtime/invoke \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents/00b00d76-1313-46cd-af96-4d9139a47641/session/6268416b-0db6-431e-ab87-d31e9a10ea13/turn/0c12d6df-314c-446d-ac68-8f1dd34475a8/resume \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/tool-runtime/invoke \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8321/v1/agents/00b00d76-1313-46cd-af96-4d9139a47641/session/6268416b-0db6-431e-ab87-d31e9a10ea13/turn/0c12d6df-314c-446d-ac68-8f1dd34475a8/resume \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 1: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m{\"thought\": \"I will create a new Docling document on Quantum Computing by using the create_new_docling_document tool with the prompt as the title of the document.\", \"action\": {\"tool_name\": \"create_new_docling_document\", \"tool_params\": [{\"name\": \"prompt\", \"value\": \"Quantum Computing\"}]}, \"answer\": null}\n",
      "\u001b[0m\n",
      "\n",
      "---------- 📍 Step 2: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\\n  \"document_key\": \"15299acfdad14d21b8a26de24e7c58b4\",\\n  \"prompt\": \"Quantum Computing\"\\n}'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n  \"document_key\": \"15299acfdad14d21b8a26de24e7c58b4\",\\n  \"prompt\": \"Quantum Computing\"\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 3: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m{\"thought\": \"I will add a title to the document.\", \"action\": {\"tool_name\": \"add_title_to_docling_document\", \"tool_params\": [{\"name\": \"document_key\", \"value\": \"15299acfdad14d21b8a26de24e7c58b4\"}, {\"name\": \"title\", \"value\": \"Quantum Computing: An Introduction\"}]}, \"answer\": null}\n",
      "\u001b[0m\n",
      "\n",
      "---------- 📍 Step 4: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\\n  \"document_key\": \"15299acfdad14d21b8a26de24e7c58b4\"\\n}'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n  \"document_key\": \"15299acfdad14d21b8a26de24e7c58b4\"\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 5: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m{\"thought\": \"I will add the first paragraph to the document.\", \"action\": {\"tool_name\": \"add_paragraph_to_docling_document\", \"tool_params\": [{\"name\": \"document_key\", \"value\": \"15299acfdad14d21b8a26de24e7c58b4\"}, {\"name\": \"paragraph\", \"value\": \"Quantum Computing is a branch of physics that studies the behavior of matter and energy at an atomic and subatomic level. It relies on the principles of quantum mechanics to explain phenomena such as superposition, entanglement, and wave-particle duality.\"}]}, \"answer\": null}\n",
      "\u001b[0m\n",
      "\n",
      "---------- 📍 Step 6: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\\n  \"document_key\": \"15299acfdad14d21b8a26de24e7c58b4\"\\n}'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n  \"document_key\": \"15299acfdad14d21b8a26de24e7c58b4\"\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 7: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m{\"thought\": \"I will add the second paragraph to the document.\", \"action\": {\"tool_name\": \"add_paragraph_to_docling_document\", \"tool_params\": [{\"name\": \"document_key\", \"value\": \"15299acfdad14d21b8a26de24e7c58b4\"}, {\"name\": \"paragraph\", \"value\": \"Quantum Computing has the potential to revolutionize many fields, including chemistry and materials science. It can be used to simulate complex systems and optimize processes, leading to breakthroughs in fields such as drug discovery and materials engineering.\"}]}, \"answer\": null}\n",
      "\u001b[0m\n",
      "\n",
      "---------- 📍 Step 8: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\\n  \"document_key\": \"15299acfdad14d21b8a26de24e7c58b4\"\\n}'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n  \"document_key\": \"15299acfdad14d21b8a26de24e7c58b4\"\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 9: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m{\"thought\": \"I will add the third paragraph to the document.\", \"action\": {\"tool_name\": \"add_paragraph_to_docling_document\", \"tool_params\": [{\"name\": \"document_key\", \"value\": \"15299acfdad14d21b8a26de24e7c58b4\"}, {\"name\": \"paragraph\", \"value\": \"Quantum Computing has the potential to revolutionize many fields, including chemistry and materials science. It can be used to simulate complex systems and optimize processes, leading to breakthroughs in fields such as drug discovery and materials engineering.\"}]}, \"answer\": null}\n",
      "\u001b[0m\n",
      "\n",
      "---------- 📍 Step 10: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\\n  \"document_key\": \"15299acfdad14d21b8a26de24e7c58b4\"\\n}'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n  \"document_key\": \"15299acfdad14d21b8a26de24e7c58b4\"\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 11: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m{\n",
      "  \"thought\": \"I will save the document by calling `save_docling_document` and return me the filepath of the saved document in markdown format provided by the last tool.\",\n",
      "  \"action\": {\n",
      "    \"tool_name\": \"save_docling_document\",\n",
      "    \"tool_params\": [\n",
      "      {\"name\": \"document_key\", \"value\": \"15299acfdad14d21b8a26de24e7c58b4\"}\n",
      "    ]\n",
      "  },\n",
      "  \"answer\": null\n",
      "}\n",
      "\u001b[0m\n",
      "\n",
      "---------- 📍 Step 12: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\\n  \"md_file\": \"/Users/dol/codes/docling-mcp/_cache/15299acfdad14d21b8a26de24e7c58b4.md\",\\n  \"json_file\": \"/Users/dol/codes/docling-mcp/_cache/15299acfdad14d21b8a26de24e7c58b4.json\"\\n}'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n  \"md_file\": \"/Users/dol/codes/docling-mcp/_cache/15299acfdad14d21b8a26de24e7c58b4.md\",\\n  \"json_file\": \"/Users/dol/codes/docling-mcp/_cache/15299acfdad14d21b8a26de24e7c58b4.json\"\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 13: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m{\"thought\": \"I will save the document by calling `save_docling_document` and return me the filepath of the saved document in markdown format provided by the last tool.\", \"action\": {\"tool_name\": \"save_docling_document\", \"tool_params\": [{\"name\": \"document_key\", \"value\": \"15299acfdad14d21b8a26de24e7c58b4\"}]}, \"answer\": \"/Users/dol/codes/docling-mcp/_cache/15299acfdad14d21b8a26de24e7c58b4.md\"}\n",
      "\u001b[0m\n",
      "========== Query processing completed ========== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent = ReActAgent(\n",
    "    client=client,\n",
    "    model=settings.inference_model,\n",
    "    tools=[\"mcp::docling\"],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": ReActOutput.model_json_schema(),\n",
    "    },\n",
    "    sampling_params=sampling_params,\n",
    ")\n",
    "\n",
    "user_prompts = [\n",
    "    \"\"\"I want you to create a new Docling document on Quantum Computing.\n",
    "    To do this, you will create a document by invoking `create_new_docling_document` with Quantum Computing as prompt.\n",
    "    Add a title and 3 paragraphs describing the topic, one by one, e.g. using the add_x_to_docling_document tools.\n",
    "    At the end of the writing, you must save the document by calling `save_docling_document` and return me the filepath of\n",
    "    the saved document in markdown format provided by the last tool.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "session_id = agent.create_session(f\"docling-session_{uuid.uuid4()}\")\n",
    "for prompt in user_prompts:\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    user_printer(prompt)\n",
    "    print(\"=\" * 50)\n",
    "    response = agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        session_id=session_id,\n",
    "        stream=settings.stream,\n",
    "    )\n",
    "    if settings.stream:\n",
    "        for log in EventLogger().log(response):\n",
    "            log.print()\n",
    "    else:\n",
    "        step_printer(\n",
    "            response.steps\n",
    "        )  # print the steps of an agent's response in a formatted way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056475c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docling-mcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
